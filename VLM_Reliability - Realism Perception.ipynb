{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f059dfec",
   "metadata": {},
   "source": [
    "### 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ff11dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor,Qwen2_5_VLForConditionalGeneration\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import os, sys, time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d76abed",
   "metadata": {},
   "source": [
    "### 2. Load the target model\n",
    "\n",
    "In this workbook (and reported in the paper), we demonstrate VLM reliability concerns of discerning image realness/authenticity in Qwen-based models. The query functions are written with the default inference setups in mind. When changing the target model, be sure to read through the code and understand how textual query and image inputs are processed. \n",
    "\n",
    "Failure to do the necessary checks may result in some errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Qwen model: select the appropriate model from huggingface hub repo.\n",
    "modelName = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
    "\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    modelName, torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff7bf3",
   "metadata": {},
   "source": [
    "### 3. Define the helper functions and the experimental setup.\n",
    "\n",
    "The noise_params dictionary object stores parameters used to control the perturbation strength. The \"direction\" of the perturbation is dependent on the current VLM score and the target threshold.\n",
    "\n",
    "The repository contains a \"test_images\" directory with some images from the RGFreq dataset - which you can download from IEEE dataport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5457d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_array(image):\n",
    "    return np.asarray(image).astype(np.float32)\n",
    "\n",
    "def array_to_image(array):\n",
    "    array = np.clip(array, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(array)\n",
    "def get_shuffled_image_list(directory, seed=42):\n",
    "    random.seed(seed)  # Ensure reproducibility\n",
    "#     image_list = os.listdir(directory)\n",
    "    random.shuffle(directory)\n",
    "    return directory\n",
    "\n",
    "noise_params = {\n",
    "    \"num_sparse_points\": 500,\n",
    "    \"sparse_noise_std\": 15000,     # default num_sparse_points + sparse_noise_std values that will be updated\n",
    "    \"min_freq_band\": 0.85,         # lower bound for high freq region\n",
    "    \"max_freq_band\": 1.00          # upper bound for high freq region\n",
    "}\n",
    "\n",
    "# images to be tested and transformed \n",
    "imageDir = './test_images/'\n",
    "\n",
    "# directory where the images will be saved\n",
    "targetDir = \"./perturbed_images/realism/\"\n",
    "\n",
    "# for quick testing of code\n",
    "maxTestImages = 100\n",
    "\n",
    "# perturbation search hyperparameters\n",
    "TARGET_REALISM_THRESHOLD = 7\n",
    "MAX_SEARCH_ITERATIONS = 5\n",
    "CANDIDATES_PER_ITERATION = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca228d0",
   "metadata": {},
   "source": [
    "### 4. Define VLM reliability implementation functions.\n",
    "\n",
    "Here, our technical contributions leverage the following function blocks.\n",
    "1. **query_model_realness**(img)\n",
    " - input is the test image. Outputs the VLM's realness prediction as an integer, given the prompt: \"*What is the likelihood that this is a real image? Give me a score out of 10. Output a single number.*\" The function constructs a Qwen-readable message, processing the text and image inputs, parsing this through the VLM.\n",
    "    \n",
    "2. **guided_frequency_search_increase_realism**(image: Image.Image, query_model_fn,target_threshold: int = 5, max_iters: int = 5, candidates_per_iter: int = 4, target_path = None,noise_params) -> (Image.Image, int)\n",
    " - This function handles the search for the optimal frequency perturbation, based on the target output and the VLM that is queried. The running code uses this function in the iterator. After spatial perturbations are applied, the VLM is queried to see if the realism likelihood has increased. This is the effective \"search\" taking place. As per the paper, we are demonstrating that imperceptible perturbations can move the VLM decision across \"*binary*\" decision boundaries\n",
    "\n",
    "3. **add_sparse_fequency_domain_noise_patch_channel**(image: Image.Image, num_sparse_points: int = 100, sparse_noise_std: float = 1500, min_freq_band: float = 0.85, max_freq_band: float = 1.00) -> Image.Image:\n",
    "- This is the spatial frequency perturbation function. Given an image and perturbation parameters, it returns a perturbed image (with the candidate perturbation applied). FFT and inverse FFT is called to transform the image to and from the frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d25f7c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def query_model_realness(img):\n",
    "    \n",
    "    # This is the prompt used for the paper.\n",
    "    prompt = \"What is the likelihood that this is a real image? Give me a score out of 10. Output a single number.\"\n",
    "    device = \"cuda\"\n",
    "    \n",
    "    # create a message structure for the VLM to read\n",
    "    message = [[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": img},\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ]]\n",
    "    \n",
    "    # process text and image inputs and send to device\n",
    "    texts = [\n",
    "        processor.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)\n",
    "        for msg in message]\n",
    "    image_inputs, video_inputs = process_vision_info(message)\n",
    "    inputs = processor(\n",
    "        text=texts,\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    # Batch Inference\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=10)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_texts = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    \n",
    "    # We typecast the output as an int to ensure that a single number is extracted.\n",
    "    # If the output is not a single number, try and output a float,\n",
    "    # else return 0 as the VLM could not return an appropriate number. \n",
    "    # This is just to catch string errors, found that the second exception would rarely arise when the default\n",
    "    # prompt is used\n",
    "    try:\n",
    "        return int(output_texts[0])\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # Try parsing as float then int\n",
    "            return int(float(output_texts[0]))\n",
    "        except ValueError:\n",
    "            # Handle if it's not even a float\n",
    "            print(f\"Warning: Cannot convert {output_texts[0]} to int. Returning 0\")\n",
    "            return 0\n",
    "\n",
    "def guided_frequency_search_increase_realism(\n",
    "    image: Image.Image,\n",
    "    query_model_fn,\n",
    "    target_threshold: int = 5,\n",
    "    max_iters: int = 5,\n",
    "    candidates_per_iter: int = 4,\n",
    "    target_path = None,\n",
    "    **noise_params\n",
    ") -> (Image.Image, int):\n",
    "    start = time.time()\n",
    "    \"\"\"\n",
    "    Guided search using frequency-domain perturbations to boost likelihood.\n",
    "\n",
    "    Parameters:\n",
    "    image (Image.Image): Input PIL image.\n",
    "    query_model_fn (function): Black-box model query function.\n",
    "    target_threshold (int): Desired likelihood score.\n",
    "    max_iters (int): Max optimization iterations.\n",
    "    candidates_per_iter (int): Number of perturbation candidates per iteration.\n",
    "    noise_params: Parameters for the noise function.\n",
    "\n",
    "    Returns:\n",
    "    (Image.Image, int): Best transformed image and final likelihood score.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hyper-parameters used for determining the sparsity and intensity of the perturbation on the image.\n",
    "    # As per the paper: σ = 0.025 × H × W , i.e., 2.5% standard deviation, proportional to input size.\n",
    "    #                   ρ = 0.1 × H × W , i.e., 10% data points transformed, proportional to input size.\n",
    "    NPix = 0.1\n",
    "    Nstd = 0.025\n",
    "    \n",
    "    # Retreive the current state of the image and the corresponding base score\n",
    "    current_image = image.copy()\n",
    "    current_score = query_model_fn(current_image)\n",
    "    \n",
    "    # Define spatial perturbation parameters and update noise parameter dictionary\n",
    "    noise_params[\"num_sparse_points\"] = int(NPix*current_image.size[0]*current_image.size[1])\n",
    "    \n",
    "    # If the image size is really small (like CIFAR-10), adjust the standard deviation parameter\n",
    "    if current_image.size[0]*current_image.size[1] < 100 * 100:\n",
    "        noise_params[\"sparse_noise_std\"] = int(Nstd*2*current_image.size[0]*current_image.size[1])\n",
    "    else:\n",
    "        noise_params[\"sparse_noise_std\"] = int(Nstd*current_image.size[0]*current_image.size[1])\n",
    "        \n",
    "    \n",
    "    # If the model already predicts that the image is likely to be real, exit early\n",
    "    if current_score >= target_threshold:\n",
    "        print(current_score, \" is already above target threshold\")\n",
    "        return current_image, current_score\n",
    "    \n",
    "    # Else: continue to iterate through for 'max_iters' number of iterations\n",
    "    print(\"original score:\\t\", current_score)\n",
    "    for iteration in range(max_iters):\n",
    "        # Empty lists to store experimental results\n",
    "        candidates = []\n",
    "        scores = []\n",
    "\n",
    "        # Generate multiple perturbation candidates\n",
    "        # At each iteration, store a candidate perturbation and the score it achieves\n",
    "        for _ in range(candidates_per_iter):\n",
    "            candidate_img = add_sparse_fequency_domain_noise_patch_channel(current_image, **noise_params)\n",
    "            score = query_model_fn(candidate_img)\n",
    "            candidates.append(candidate_img)\n",
    "            scores.append(score)\n",
    "        print(\"iteration:\\t\", iteration)\n",
    "        print(\"scores:\\t\\t\", scores)\n",
    "\n",
    "        # For increasing realism likelihood, the best score is the maximum value achieved\n",
    "        best_idx = np.argmax(scores)\n",
    "        best_candidate_score = scores[best_idx]\n",
    "\n",
    "        # Only move if there's an improvement\n",
    "        if best_candidate_score >= current_score:\n",
    "            current_image = candidates[best_idx]\n",
    "            current_score = best_candidate_score\n",
    "\n",
    "        print(\"current score:\\t\",current_score,\"\\n\")\n",
    "        current_image.save(target_path)\n",
    "        # Stop if target is reached\n",
    "        if current_score >= target_threshold:\n",
    "            break\n",
    "        \n",
    "        # For debugging and logging implementation time.\n",
    "        end = time.time()\n",
    "        print(f\"Took {end - start:.4f} seconds\")\n",
    "    return current_image, current_score\n",
    "\n",
    "def add_sparse_fequency_domain_noise_patch_channel(\n",
    "    image: Image.Image,\n",
    "    num_sparse_points: int = 100,\n",
    "    sparse_noise_std: float = 1500,\n",
    "    min_freq_band: float = 0.85,\n",
    "    max_freq_band: float = 1.00\n",
    ") -> Image.Image:\n",
    "    \"\"\"\n",
    "    Adds sparse noise in a selected frequency band of the image's frequency domain.\n",
    "\n",
    "    Parameters:\n",
    "    image (Image.Image): Input PIL image.\n",
    "    num_sparse_points (int): Number of sparse frequency points to modify.\n",
    "    sparse_noise_std (float): Std dev of Gaussian noise to apply.\n",
    "    min_freq_band (float): Min frequency band (as fraction of max radius).\n",
    "    max_freq_band (float): Max frequency band (as fraction of max radius).\n",
    "\n",
    "    Returns:\n",
    "    Image.Image: Image with frequency-domain sparse noise applied.\n",
    "    \"\"\"\n",
    "    image_np = np.array(image)\n",
    "    try:\n",
    "        height, width, channels = image_np.shape\n",
    "    except ValueError:\n",
    "        image_np= np.stack([image_np] * 3, axis=-1)\n",
    "        height, width, channels = image_np.shape\n",
    "    cy, cx = height // 2, width // 2\n",
    "\n",
    "    for c in range(channels):\n",
    "        channel = image_np[:, :, c]\n",
    "\n",
    "        # DFT and center-shift\n",
    "        dft = np.fft.fft2(channel)\n",
    "        dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "        # Frequency band selection\n",
    "        Y, X = np.ogrid[:height, :width]\n",
    "        distance = np.sqrt((X - cx)**2 + (Y - cy)**2)\n",
    "        max_radius = np.max(distance)\n",
    "        min_thresh = min_freq_band * max_radius\n",
    "        max_thresh = max_freq_band * max_radius\n",
    "\n",
    "        # Mask bandpass region\n",
    "        band_mask = (distance >= min_thresh) & (distance <= max_thresh)\n",
    "        band_indices = np.argwhere(band_mask)\n",
    "\n",
    "        # Select sparse positions to perturb\n",
    "        selected_indices = band_indices[np.random.choice(\n",
    "            band_indices.shape[0],\n",
    "            size=min(num_sparse_points, len(band_indices)),\n",
    "            replace=False\n",
    "        )]\n",
    "\n",
    "        for y_idx, x_idx in selected_indices:\n",
    "            dft_shift[y_idx, x_idx] += np.random.normal(0, sparse_noise_std)\n",
    "\n",
    "        # Inverse transform\n",
    "        dft_ishift = np.fft.ifftshift(dft_shift)\n",
    "        img_back = np.fft.ifft2(dft_ishift)\n",
    "        img_back = np.abs(img_back)\n",
    "        image_np[:, :, c] = np.clip(img_back, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return Image.fromarray(image_np)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6379b535",
   "metadata": {},
   "source": [
    "### 5. Running Code (Increasing Realism Perception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e809cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image in the test image directory\n",
    "for ii, fp in enumerate(get_shuffled_image_list(os.listdir(imageDir))):\n",
    "    if ii < maxTestImages:\n",
    "        \n",
    "        if fp.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\")):\n",
    "            input_image = Image.open(imageDir + fp)\n",
    "\n",
    "            # Apply spatial frequency transformation on images, returning the optimal perturbed image\n",
    "            transformed_image, final_score = guided_frequency_search_increase_realism(\n",
    "                input_image,\n",
    "                query_model_fn=query_model_realness,\n",
    "                target_threshold=TARGET_REALISM_THRESHOLD,\n",
    "                max_iters=MAX_SEARCH_ITERATIONS,\n",
    "                candidates_per_iter=CANDIDATES_PER_ITERATION,\n",
    "                target_path=targetDir+fp,\n",
    "                **noise_params\n",
    "            )\n",
    "            if transformed_image is not None:\n",
    "                print(f\"Final Likelihood Score: {final_score}\")\n",
    "                transformed_image.save(targetDir+fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5495a9",
   "metadata": {},
   "source": [
    "### 6. Decreasing Realism Perception\n",
    "\n",
    "Evaluating the performance on generated images and making VLMs perceptions 'more realistic' is one part of the problem. To ensure that the approach is valid, we also demonstrate how perceptions of realism can be reduced by applying transformations to move the VLM decision in the opposite direction. To do this, we need a second guided_frequency search function that looks to minimize the realism likelihood score. Once this function is defined, we implement a new running code on the test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f06b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guided_frequency_search_decrease_realism(\n",
    "    image: Image.Image,\n",
    "    query_model_fn,\n",
    "    target_threshold: int = 5,\n",
    "    max_iters: int = 5,\n",
    "    candidates_per_iter: int = 4,\n",
    "    target_path = None,\n",
    "    **noise_params\n",
    ") -> (Image.Image, int):\n",
    "    \"\"\"\n",
    "    Guided search using frequency-domain perturbations to boost likelihood.\n",
    "\n",
    "    Parameters:\n",
    "    image (Image.Image): Input PIL image.\n",
    "    query_model_fn (function): Black-box model query function.\n",
    "    target_threshold (int): Desired likelihood score.\n",
    "    max_iters (int): Max optimization iterations.\n",
    "    candidates_per_iter (int): Number of perturbation candidates per iteration.\n",
    "    noise_params: Parameters for the noise function.\n",
    "\n",
    "    Returns:\n",
    "    (Image.Image, int): Best transformed image and final likelihood score.\n",
    "    \"\"\"\n",
    "    NPix = 0.2\n",
    "    Nstd = 0.025\n",
    "    current_image = image.copy()\n",
    "    current_score = query_model_fn(current_image)\n",
    "    noise_params[\"num_sparse_points\"] = int(NPix*current_image.size[0]*current_image.size[1])\n",
    "    noise_params[\"sparse_noise_std\"] = int(Nstd*current_image.size[0]*current_image.size[1])\n",
    "\n",
    "    if current_score <= target_threshold:\n",
    "        print(current_score, \" is already above target threshold\")\n",
    "        return current_image, current_score\n",
    "    print(\"original score:\\t\", current_score)\n",
    "    for iteration in range(max_iters):\n",
    "        candidates = []\n",
    "        scores = []\n",
    "\n",
    "        # Generate multiple perturbation candidates\n",
    "        for _ in range(candidates_per_iter):\n",
    "            candidate_img = add_sparse_fequency_domain_noise_patch_channel(current_image, **noise_params)\n",
    "            score = query_model_fn(candidate_img)\n",
    "            candidates.append(candidate_img)\n",
    "            scores.append(score)\n",
    "        print(\"iteration:\\t\", iteration)\n",
    "        print(\"scores:\\t\\t\", scores)\n",
    "\n",
    "        best_idx = np.argmin(scores)\n",
    "        best_candidate_score = scores[best_idx]\n",
    "\n",
    "        # Only move if there's an improvement\n",
    "        if best_candidate_score <= current_score:\n",
    "            current_image = candidates[best_idx]\n",
    "            current_score = best_candidate_score\n",
    "\n",
    "        print(\"current score:\\t\",current_score,\"\\n\")\n",
    "        try:\n",
    "            current_image.save(target_path)\n",
    "        except OSError:\n",
    "            current_image = current_image.convert(\"RGB\")\n",
    "            current_image.save(target_path)\n",
    "        # Stop if target is reached\n",
    "        if current_score <= target_threshold:\n",
    "            break\n",
    "\n",
    "    return current_image, current_score\n",
    "\n",
    "# updated perturbation search hyperparameters\n",
    "TARGET_REALISM_THRESHOLD = 4\n",
    "MAX_SEARCH_ITERATIONS = 5\n",
    "CANDIDATES_PER_ITERATION = 10\n",
    "\n",
    "# images to be tested and transformed \n",
    "imageDir = './test_images/'\n",
    "\n",
    "# directory where the images will be saved\n",
    "targetDir = \"./perturbed_images/realism/\"\n",
    "\n",
    "\n",
    "# for each image in the test image directory\n",
    "for ii, fp in enumerate(get_shuffled_image_list(os.listdir(imageDir))):\n",
    "    if ii < maxTestImages:\n",
    "        \n",
    "        if fp.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\")):\n",
    "            input_image = Image.open(imageDir + fp)\n",
    "            \n",
    "            # Apply spatial frequency transformation on images, returning the optimal perturbed image\n",
    "            transformed_image, final_score = guided_frequency_search_decrease_realism(\n",
    "                input_image,\n",
    "                query_model_fn=query_model_realness,\n",
    "                target_threshold=TARGET_REALISM_THRESHOLD,\n",
    "                max_iters=MAX_SEARCH_ITERATIONS,\n",
    "                candidates_per_iter=CANDIDATES_PER_ITERATION,\n",
    "                target_path=targetDir+fp,\n",
    "                **noise_params)\n",
    "            if transformed_image is not None:\n",
    "                print(f\"Final Likelihood Score: {final_score}\")\n",
    "                transformed_image.save(targetDir+fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Py3916Env] *",
   "language": "python",
   "name": "conda-env-Py3916Env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
